{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maimuna-noshin/Solar_Prediction/blob/main/solarprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "vQ2XqW7kluLE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pickle\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, BatchNormalization, Flatten, Bidirectional, LayerNormalization, Input, Layer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.fftpack import fft\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.models import Sequential, Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/updated_dataset.csv\")"
      ],
      "metadata": {
        "id": "b2EaJDk9l9JD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to datetime\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour']])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8eWPZASsl9Mm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting features (X) and target variables (Y)\n",
        "features = ['Hour', 'Temperature_A','Pressure_A', 'Day','Month', 'Surface Albedo_A', 'Cloud Type_A']\n",
        "targets = ['DNI_A']  # Target variables for all three locations"
      ],
      "metadata": {
        "id": "jrLXHLggl9TK"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df[features].values\n",
        "y = df[targets].values"
      ],
      "metadata": {
        "id": "qSIvZNBO2RrP"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep timestamps before scaling\n",
        "timestamps = df[['Month', 'Day', 'Hour']]"
      ],
      "metadata": {
        "id": "QK_c9pUC2R1G"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hours_tensor = tf.convert_to_tensor(df['Hour'].values, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "PQecOZDwu71w"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_fixed(y_true, y_pred):\n",
        "    batch_size = tf.shape(y_true)[0]\n",
        "    batch_hours = tf.gather(hours_tensor, tf.range(batch_size))  # Use hours_tensor instead of hours\n",
        "\n",
        "    nighttime_mask = tf.logical_or(tf.less_equal(batch_hours, 8), tf.greater_equal(batch_hours, 18))\n",
        "    nighttime_mask = tf.cast(nighttime_mask, tf.float32)\n",
        "\n",
        "    mse_loss = tf.keras.losses.MSE(y_true, y_pred)\n",
        "    penalty_factor = 50.0\n",
        "    weighted_loss = mse_loss * (1 + (penalty_factor - 1) * nighttime_mask)\n",
        "\n",
        "    return tf.reduce_mean(weighted_loss)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TXzT_iAmLeVi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_X = MinMaxScaler()\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1000))\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "# Save the feature scaler\n",
        "with open(\"scaler_X.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler_X, f)\n",
        "\n",
        "# Save the target scaler\n",
        "with open(\"scaler_y.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler_y, f)\n",
        "# Create binary classification labels (0 if DNI_A == 0, 1 if DNI_A > 0)\n",
        "y_class = (y > 0).astype(int)\n"
      ],
      "metadata": {
        "id": "hQ2Kq3h82R42"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureAttention(Layer):\n",
        "    def __init__(self, feature_dim):\n",
        "        super(FeatureAttention, self).__init__()\n",
        "        self.feature_weights = Dense(feature_dim, activation=\"softmax\")  # Learnable feature weights\n",
        "\n",
        "    def call(self, inputs):\n",
        "        weights = self.feature_weights(inputs)  # Generate importance scores\n",
        "        return inputs * weights  # Apply attention weights to features\n",
        "\n",
        "\n",
        "# Define input\n",
        "input_features = Input(shape=(X_train_class.shape[1],))\n",
        "\n",
        "# Apply feature attention\n",
        "x = FeatureAttention(X_train_class.shape[1])(input_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "ed-wFhnHj0ZI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split Data for classification\n",
        "X_train_class, X_test_class, y_train_class, y_test_class, timestamps_train, timestamps_test= train_test_split(X_scaled, y_class,timestamps, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EZ3DTavB2R8l"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_shape=(X_train_class.shape[1],)),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")  # Binary classification\n",
        "])\n",
        "\n",
        "\n",
        "classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "classifier.fit(X_train_class, y_train_class, epochs=10, batch_size=8, validation_data=(X_test_class, y_test_class))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztt3RdnS2g_8",
        "outputId": "e70095f5-9485-4f72-96af-729c2029c5de",
        "collapsed": true
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.4525 - val_accuracy: 0.9207 - val_loss: 0.2125\n",
            "Epoch 2/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1488 - val_accuracy: 0.9372 - val_loss: 0.1380\n",
            "Epoch 3/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1257 - val_accuracy: 0.9441 - val_loss: 0.1389\n",
            "Epoch 4/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1260 - val_accuracy: 0.9509 - val_loss: 0.1277\n",
            "Epoch 5/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1154 - val_accuracy: 0.9395 - val_loss: 0.1410\n",
            "Epoch 6/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1114 - val_accuracy: 0.9503 - val_loss: 0.1105\n",
            "Epoch 7/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1023 - val_accuracy: 0.9298 - val_loss: 0.1696\n",
            "Epoch 8/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1196 - val_accuracy: 0.9572 - val_loss: 0.1163\n",
            "Epoch 9/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1001 - val_accuracy: 0.9509 - val_loss: 0.1151\n",
            "Epoch 10/10\n",
            "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1024 - val_accuracy: 0.9526 - val_loss: 0.1041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa0441898d0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct Boolean Masking for Selecting Nonzero DNI_A Cases\n",
        "daytime_mask = y > 0  # Creates a boolean mask where DNI_A > 0\n",
        "X_day = X_scaled[daytime_mask.flatten()]  # Apply mask to X_scaled\n",
        "y_day = y[daytime_mask]  # Apply mask to y\n"
      ],
      "metadata": {
        "id": "4FwmcYCrriGA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data for Regression\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_day, y_day, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "und47TquuScL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regressor Model (Predicts DNI_A for nonzero cases)\n",
        "regressor = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_shape=(X_train_reg.shape[1],)),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(1, activation=\"linear\")\n",
        "])\n",
        "\n",
        "regressor.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "regressor.fit(X_train_reg, y_train_reg, epochs=10, batch_size=8, validation_data=(X_test_reg, y_test_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8ba45bekqK6",
        "outputId": "e7b84e36-39aa-4bde-9f21-0cc0d3533236"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 127656.0391 - mae: 292.9804 - val_loss: 45222.1953 - val_mae: 175.0984\n",
            "Epoch 2/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45256.9961 - mae: 177.8821 - val_loss: 43435.4414 - val_mae: 173.5189\n",
            "Epoch 3/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45377.7031 - mae: 179.5972 - val_loss: 42015.1250 - val_mae: 168.9384\n",
            "Epoch 4/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 44775.3633 - mae: 176.2328 - val_loss: 41695.5117 - val_mae: 168.0025\n",
            "Epoch 5/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42749.6836 - mae: 170.8375 - val_loss: 42679.6055 - val_mae: 170.5564\n",
            "Epoch 6/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42554.0859 - mae: 172.1966 - val_loss: 41356.7188 - val_mae: 166.3071\n",
            "Epoch 7/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41751.4258 - mae: 168.3298 - val_loss: 41235.3164 - val_mae: 166.1193\n",
            "Epoch 8/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41294.2930 - mae: 168.4694 - val_loss: 41169.7070 - val_mae: 166.0417\n",
            "Epoch 9/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 43919.9727 - mae: 173.9943 - val_loss: 41143.1523 - val_mae: 165.8974\n",
            "Epoch 10/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 42076.1367 - mae: 170.2580 - val_loss: 41491.8945 - val_mae: 165.7574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa044220b50>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probability of nonzero irradiance\n",
        "is_daytime_mask = classifier.predict(X_test_class) > 0.48  # Boolean mask for daytime\n",
        "\n",
        "# Ensure X_test_reg and is_daytime_mask have compatible sizes\n",
        "min_size = min(len(is_daytime_mask), len(X_test_reg))\n",
        "is_daytime_mask = is_daytime_mask[:min_size]\n",
        "X_test_reg = X_test_reg[:min_size]\n",
        "\n",
        "# Filter indices where it's daytime\n",
        "daytime_indices = np.where(is_daytime_mask)[0]\n",
        "\n",
        "# Predict irradiance only for daytime cases\n",
        "X_test_reg_daytime = X_test_reg[daytime_indices]  # Select only daytime data\n",
        "irradiance_predictions = regressor.predict(X_test_reg_daytime).flatten()\n",
        "\n",
        "# Initialize final prediction array with zeros\n",
        "y_pred = np.zeros(min_size, dtype=float)\n",
        "\n",
        "# Assign irradiance predictions only to daytime indices\n",
        "y_pred[daytime_indices] = irradiance_predictions  # Map regression predictions correctly\n",
        "\n",
        "# Convert predictions into a DataFrame with timestamps\n",
        "predictions_df = timestamps_test.iloc[:min_size].copy()\n",
        "predictions_df[\"DNI_A\"] = y_pred  # Assign predicted irradiance\n",
        "\n",
        "# Print first 100 predictions with date and hour\n",
        "print(predictions_df.head(100))\n",
        "\n",
        "# Save predictions to CSV\n",
        "predictions_df.to_csv(\"solar_irradiance_predictions.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "8IdbseJv3CKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecb53d2-5bed-4ad9-fd5c-d37bb5b1d0ef"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "      Month  Day  Hour       DNI_A\n",
            "6056      9   10     8  426.797882\n",
            "5556      8   20    12  355.509216\n",
            "5990      9    7    14  298.844269\n",
            "7674     11   16    18    0.000000\n",
            "3319      5   19     7  282.820038\n",
            "...     ...  ...   ...         ...\n",
            "6006      9    8     6    0.000000\n",
            "8063     12    2    23    0.000000\n",
            "14        1    1    14  288.338837\n",
            "5306      8   10     2    0.000000\n",
            "8524     12   22     4    0.000000\n",
            "\n",
            "[100 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the classifier model\n",
        "classifier.save(\"solar_classifier.keras\")\n",
        "\n",
        "# Save the regressor model\n",
        "regressor.save(\"solar_regressor.keras\")"
      ],
      "metadata": {
        "id": "puUcFKZDAnOu"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load the scalers used during training\n",
        "\n",
        "with open(\"scaler_X.pkl\", \"rb\") as f:\n",
        "    scaler_X = pickle.load(f)\n",
        "with open(\"scaler_y.pkl\", \"rb\") as f:\n",
        "    scaler_y = pickle.load(f)"
      ],
      "metadata": {
        "id": "gZGmN3-zAnR0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate timestamps for the first week of March 2025 (hourly)\n",
        "date_range = pd.date_range(start=\"2025-03-01\", end=\"2025-03-07 23:00:00\", freq=\"H\")\n",
        "future_df = pd.DataFrame({\"datetime\": date_range})"
      ],
      "metadata": {
        "id": "7-2OXJ9dArho",
        "outputId": "a3b34252-60f1-45e7-de82-9b9a61b9c49f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-0e223ba96d09>:2: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  date_range = pd.date_range(start=\"2025-03-01\", end=\"2025-03-07 23:00:00\", freq=\"H\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Feature Engineering\n",
        "future_df[\"day\"] = future_df[\"datetime\"].dt.day\n",
        "future_df[\"month\"] = future_df[\"datetime\"].dt.month\n",
        "future_df[\"hour\"] = future_df[\"datetime\"].dt.hour\n",
        "future_df.drop(columns=[\"datetime\"], inplace=True)"
      ],
      "metadata": {
        "id": "G55MNz34AnVq"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random values\n",
        "future_df[\"Temperature_A\"] = np.random.uniform(27, 30, size=168)  # Temperature between 15°C to 30°C\n",
        "future_df[\"Pressure_A\"] = np.random.uniform(1000, 1050, size=168)  # Pressure between 950-1050 hPa\n",
        "future_df[\"Surface Albedo_A\"] = np.random.uniform(0.1, 0.5, size=168)  # Albedo between 0.1 - 0.5\n",
        "future_df[\"Cloud Type_A\"] = np.random.randint(0, 4, size=168)  # Cloud types (0-3)\n",
        "\n",
        "# Merge the first week’s random values with `future_df`\n",
        "#future_df = future_df.merge(future_df, on=[\"Month\", \"Day\"], how=\"left\")\n",
        "\n",
        "# Time-based encoding (sin/cos transformation)\n",
        "#future_df[\"hour_sin\"] = np.sin(2 * np.pi * future_df[\"hour\"] / 24)\n",
        "#future_df[\"hour_cos\"] = np.cos(2 * np.pi * future_df[\"hour\"] / 24)\n",
        "\n",
        "# Select the same features used in training\n",
        "#X_future = future_df[['hour_sin', 'hour_cos', 'Temperature_A', 'Pressure_A', 'day', 'Month', 'Surface Albedo_A', 'Cloud Type_A']].values"
      ],
      "metadata": {
        "id": "e7HqObYi70BB"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Select the same features used in training\n",
        "X_future = future_df[['hour', 'Temperature_A','Pressure_A', 'day','month', 'Surface Albedo_A', 'Cloud Type_A']].values\n",
        "#  Scale future data using the trained scaler\n",
        "X_future_scaled = scaler_X.transform(X_future)\n",
        "print(X_future_scaled)\n"
      ],
      "metadata": {
        "id": "_hgX_tASA1fh",
        "outputId": "110395bf-826a-4060-95d1-0cca9eef94f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.60261341  1.79249407 ...  0.18181818  1.09835445\n",
            "   0.22222222]\n",
            " [ 0.04347826  0.65531961  1.06460368 ...  0.18181818 -0.07951387\n",
            "   0.11111111]\n",
            " [ 0.08695652  0.58369543  0.64415349 ...  0.18181818  0.30208036\n",
            "   0.33333333]\n",
            " ...\n",
            " [ 0.91304348  0.64779689  0.42068025 ...  0.18181818  5.51593665\n",
            "   0.11111111]\n",
            " [ 0.95652174  0.6524072   0.83999401 ...  0.18181818  1.55423864\n",
            "   0.33333333]\n",
            " [ 1.          0.6657793   1.83712311 ...  0.18181818  0.4978481\n",
            "   0.11111111]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probability of nonzero irradiance\n",
        "is_daytime_future = classifier.predict(X_future_scaled) > 0.48  # Boolean mask for daytime\n",
        "\n",
        "# Ensure X_future_scaled and is_daytime_future have compatible sizes\n",
        "min_size_future = min(len(is_daytime_future), len(X_future_scaled))\n",
        "is_daytime_future = is_daytime_future[:min_size_future]\n",
        "X_future_scaled = X_future_scaled[:min_size_future]\n",
        "\n",
        "# Filter indices where it's daytime\n",
        "daytime_indices_future = np.where(is_daytime_future)[0]\n",
        "\n",
        "# Predict irradiance only for daytime cases\n",
        "X_future_scaled_daytime = X_future_scaled[daytime_indices_future]\n",
        "irradiance_future_scaled = regressor.predict(X_future_scaled_daytime).flatten()\n",
        "\n",
        "# Initialize final prediction array with zeros\n",
        "y_future_scaled = np.zeros(min_size_future, dtype=float)\n",
        "\n",
        "# Assign irradiance predictions only to daytime indices\n",
        "y_future_scaled[daytime_indices_future] = irradiance_future_scaled\n",
        "\n",
        "# Inverse scale predictions\n",
        "y_future = scaler_y.inverse_transform(y_future_scaled.reshape(-1, 1))\n",
        "\n",
        "# Set small irradiance values to 0\n",
        "y_future[y_future < 15] = 0  # Adjust threshold if needed\n",
        "\n"
      ],
      "metadata": {
        "id": "j9fFf3iAA19-",
        "outputId": "c84ac848-7d1a-466b-dd13-66c33ed4d878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions to DataFrame\n",
        "future_df[['DNI_A']] = y_future\n",
        "\n",
        "#  Save to CSV\n",
        "future_df.to_csv(\"Future_Solar_Predictions_March2025.csv\", index=False)\n",
        "\n",
        "#Display first 10 predictions\n",
        "print(future_df.head(10))"
      ],
      "metadata": {
        "id": "GbNNMPFzBAEQ",
        "outputId": "95a814cd-6bf6-4e03-9438-05695fc536a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  month  hour  Temperature_A   Pressure_A  Surface Albedo_A  \\\n",
            "0    1      3     0      27.845197  1044.774822          0.194918   \n",
            "1    1      3     1      29.563419  1022.938110          0.136024   \n",
            "2    1      3     2      27.228471  1010.324605          0.155104   \n",
            "3    1      3     3      29.001797  1032.110013          0.334024   \n",
            "4    1      3     4      27.527396  1038.896421          0.444265   \n",
            "5    1      3     5      29.195919  1046.968741          0.321726   \n",
            "6    1      3     6      27.028032  1043.307186          0.208534   \n",
            "7    1      3     7      28.829989  1005.648000          0.119935   \n",
            "8    1      3     8      28.348895  1035.582038          0.106579   \n",
            "9    1      3     9      27.560904  1023.433470          0.372074   \n",
            "\n",
            "   Cloud Type_A       DNI_A  \n",
            "0             2    0.000000  \n",
            "1             1    0.000000  \n",
            "2             3    0.000000  \n",
            "3             1    0.000000  \n",
            "4             2    0.000000  \n",
            "5             2    0.000000  \n",
            "6             0    0.000000  \n",
            "7             1  287.695168  \n",
            "8             3  497.971771  \n",
            "9             0    0.000000  \n"
          ]
        }
      ]
    }
  ]
}